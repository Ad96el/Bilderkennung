{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing SS 20 - Assignment - 09\n",
    "\n",
    "### Deadline is 24.6.2020 at 11:55am\n",
    "\n",
    "Please solve the assignments together with a partner.\n",
    "I will run every notebook. Make sure the code runs through. Select `Kernel` -> `Restart & Run All` to test it.\n",
    "Please strip the output from the cells, either select `Cell` -> `All Output` -> `Clear` or use the `nb_strip_output.py` script / git hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the plots inside the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from scipy.fftpack import dct, idct\n",
    "from skimage.data import chelsea\n",
    "import zipfile\n",
    "pylab.rcParams['figure.figsize'] = (15, 15)   # This makes the plot bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG\n",
    "\n",
    "The Wikipedia page about [JPEG-Komprimierung](https://de.wikipedia.org/wiki/JPEG#Die_JPEG-Komprimierung) gives\n",
    "a good overview. Wikipedia assume that the image data is uint8. That is why we do not convert it to float in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the input image\n",
    "img = chelsea()\n",
    "\n",
    "block_size = 8\n",
    "# add some padding so the image can be evenly sliced into blocks\n",
    "pad_x = 0 if img.shape[0] % (block_size * 2) == 0 else (img.shape[0] // (block_size * 2) + 1) * (block_size * 2) - img.shape[0]\n",
    "pad_y = 0 if img.shape[1] % (block_size * 2) == 0 else (img.shape[1] // (block_size * 2) + 1) * (block_size * 2) - img.shape[1]\n",
    "img = np.pad(img, ((0, pad_x), (0, pad_y), (0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Blocks:\n",
    "    \"\"\"Transforms an image to blocks. A (512, 512) image will become an (64, 64, 8, 8) numpy array\"\"\"\n",
    "    def __init__(self, block_size=8):\n",
    "        self.block_size = block_size\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        b = self.block_size\n",
    "        height, width = img.shape\n",
    "\n",
    "        assert img.shape[0] % b == 0\n",
    "        assert img.shape[1] % b == 0\n",
    "        blocks = np.zeros((height // b, width // b, b, b), dtype=img.dtype)\n",
    "        for i in range(0, height // b):\n",
    "            for j in range(0, width // b):\n",
    "                blocks[i, j] = img[i*b:(i+1)*b, j*b:(j+1)*b]\n",
    "        return blocks\n",
    "\n",
    "    def invert(self, blocks):\n",
    "        bh, bw = blocks.shape[:2]\n",
    "        b = self.block_size\n",
    "        heigth, width = (bh*self.block_size, bw*self.block_size)\n",
    "\n",
    "        img = np.zeros((heigth, width), dtype=blocks.dtype)\n",
    "        for i in range(0, bh):\n",
    "            for j in range(0, bw):\n",
    "                img[i*b:(i+1)*b, j*b:(j+1)*b] = blocks[i, j]\n",
    "        return img\n",
    "\n",
    "# test block operation on R-Channel\n",
    "img_blocks = Blocks(block_size=8)(img[:, :, 0])\n",
    "print(img_blocks.shape)\n",
    "assert img_blocks.shape[2:] == (8, 8)\n",
    "img_inv = Blocks(block_size=8).invert(img_blocks)\n",
    "\n",
    "# the two images should be the same again after inverting\n",
    "assert (img[:, :, 0] == img_inv).all()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[:, :, 0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_inv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy encoding\n",
    "This class applies the zigzag algorithm to compress the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ZigZag:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \"\"\"Adapted from here: https://rosettacode.org/wiki/Zig-zag_matrix#Python\"\"\"\n",
    "        def key(pair):\n",
    "            x, y = pair\n",
    "            return x+y, -y if (x+y) % 2 else y\n",
    "\n",
    "        n = 8\n",
    "        indexorder = sorted(((x,y) for x in range(n) for y in range(n)), key=key)\n",
    "        self.xs = np.zeros((self.n**2,), dtype=np.int)\n",
    "        self.ys = np.zeros((self.n**2,), dtype=np.int)\n",
    "        self.back = np.zeros((n, n), dtype=np.int)\n",
    "        for i, (x, y) in enumerate(indexorder):\n",
    "            self.xs[i] = x\n",
    "            self.ys[i] = y\n",
    "            self.back[x, y] = i\n",
    "            \n",
    "    def __call__(self, blocks):\n",
    "        bh, bw, h, w = blocks.shape\n",
    "        zigzack_blocks = np.zeros((bh, bw, h*w), dtype=blocks.dtype)\n",
    "        for i, block_row in enumerate(blocks):\n",
    "            for j, block in enumerate(block_row):\n",
    "                zigzack_blocks[i, j] = block[self.xs, self.ys] \n",
    "        return zigzack_blocks\n",
    "    \n",
    "    def invert(self, zigzack_blocks):\n",
    "        bh, bw, hw = zigzack_blocks.shape\n",
    "        h = int(np.sqrt(hw))\n",
    "        blocks = np.zeros((bh, bw, h, h), dtype=zigzack_blocks.dtype)\n",
    "        for i, zigzack_row in enumerate(zigzack_blocks):\n",
    "            for j, zigzack in enumerate(zigzack_row):\n",
    "                blocks[i, j] = zigzack[self.back] \n",
    "        return blocks\n",
    "\n",
    "zigzag = ZigZag(8)\n",
    "range_mat = np.arange(64).reshape(1, 1, 8, 8)\n",
    "zigzack_mat = zigzag(range_mat)\n",
    "assert (zigzag.invert(zigzack_mat) == range_mat).all()\n",
    "\n",
    "print(range_mat)\n",
    "print(zigzack_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jpeg:\n",
    "    def __init__(self, stages):\n",
    "        self.stages = stages\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        y, cb, cr = ChromaSubsampling()(img)\n",
    "        outputs = []\n",
    "        for input in [y, cb, cr]:\n",
    "            output = input\n",
    "            for stage in self.stages:\n",
    "                input = output\n",
    "                try:\n",
    "                    output = stage(input)\n",
    "                except:\n",
    "                    print(\"Error in Stage: {}\".format(type(stage).__name__))\n",
    "                    raise\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        outputs = []\n",
    "        for output in inputs:\n",
    "            for stage in self.stages[::-1]:\n",
    "                input = output\n",
    "                try:\n",
    "                    output = stage.invert(input)\n",
    "                except:\n",
    "                    print(\"Error in Stage: {}\".format(type(stage).__name__))\n",
    "                    raise\n",
    "            outputs.append(output)\n",
    "        y, cb, cr = outputs\n",
    "        return ChromaSubsampling().invert([y, cb, cr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compress:\n",
    "    \"\"\"This class compresses arbitray input using the bz2 algorithm\"\"\"\n",
    "    def __init__(self, dtype=np.int8):\n",
    "        self.dtype = dtype\n",
    "        self.max_value = (np.iinfo(dtype).max  / 1.1)\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        # print(\"dtype: {}\".format(arr.dtype))\n",
    "        # print(\"max: {}, min: {}\".format(arr.max(), arr.min()))\n",
    "        scale = max(abs(arr.max()), abs(arr.min()))\n",
    "        arr = arr / scale \n",
    "        arr = arr * self.max_value\n",
    "        arr = np.rint(arr)\n",
    "        arr = arr.astype(self.dtype)\n",
    "        bytearr = arr.data.tobytes()\n",
    "        \n",
    "        return zipfile.bz2.compress(bytearr), arr.shape, arr.dtype, scale\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        bytearr, shape, dtype, scale = inputs\n",
    "        decom_bytes = zipfile.bz2.decompress(bytearr)\n",
    "        arr = np.frombuffer(decom_bytes, dtype=self.dtype)\n",
    "        arr = arr.astype(dtype)\n",
    "        arr = arr / self.max_value * scale\n",
    "        return arr.reshape(shape)\n",
    "\n",
    "range_mat = np.arange(64, dtype=np.float64).reshape(1, 1, 8, 8)\n",
    "compress = Compress()\n",
    "compressed = compress(range_mat)\n",
    "# print((compress.invert(compressed)))\n",
    "assert np.allclose(compress.invert(compressed), range_mat, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_size_jpeg(jpeg_output):\n",
    "    \"\"\"Summs the number of bytes over the different compression channels: y, cb, cr\"\"\"\n",
    "    nb_bytes = sum([len(x[0]) for x in jpeg_output])\n",
    "    return (nb_bytes / 1000)\n",
    "\n",
    "def total_size_numpy(arr):\n",
    "    return (len(arr.data.tobytes()) / 1000)\n",
    "\n",
    "def naive_compression_size(arr):\n",
    "    bytearr = arr.data.tobytes()\n",
    "    nb_bytes = len(zipfile.bz2.compress(bytearr))\n",
    "    return (nb_bytes / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chromasubsampling_compression = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=50), ZigZag(8), Compress(np.int8)])\n",
    "print(\"No compression: \" + str(total_size_numpy(img)) )\n",
    "print(\"Direct compression of the image: \" + str(naive_compression_size(img)))\n",
    "print(\"Cromasubsampling and compression: \" + str(total_size_jpeg(chromasubsampling_compression(img))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 1 - Chroma Subsampling - 2 Points\n",
    "Apply chroma subsampling to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ycbcr2rgb(im):\n",
    "    xform = np.array([[1, 0, 1.402], [1, -0.34414, -.71414], [1, 1.772, 0]])\n",
    "    rgb = im.astype(np.float)\n",
    "    rgb[:,:,[1,2]] -= 128\n",
    "    rgb = rgb.dot(xform.T)\n",
    "    np.putmask(rgb, rgb > 255, 255)\n",
    "    np.putmask(rgb, rgb < 0, 0)\n",
    "    return np.uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaSubsampling:\n",
    "    \"\"\"See https://en.wikipedia.org/wiki/YCbCr.\"\"\"\n",
    "    ycbcr = np.array([\n",
    "        [0.299,  0.587,  0.114],\n",
    "        [-0.168736, -0.331264,  0.5],\n",
    "        [0.5, -0.418688, -0.0813],\n",
    "    ])\n",
    "    def __call__(self, rgb_img):\n",
    "        \"\"\"Transforms the rgb image to YCbCr. The cb and cr channels have half the resolution of the Y-channel.\n",
    "           You can simply use the mean of four neighbours.\n",
    "        \"\"\"\n",
    "        shape = rgb_img.shape\n",
    "        \n",
    "        ycbcr_img = np.dot(self.ycbcr, rgb_img.reshape(-1, 3).T)\n",
    "        ycbcr_img = ycbcr_img.T.reshape(shape)\n",
    "        ycbcr_img[:,:, [1,2]] += 128\n",
    "        # subsample the cb and cr channel, so that they have half the resolution of the Y-channel.\n",
    "        # A simple thing might be to use the mean of 4 neighbours.\n",
    "        # use 4:2:0 \n",
    "        cb = ycbcr_img[:,:,1]\n",
    "        cr = ycbcr_img[:,:,2]\n",
    "        for i in range(0,shape[0],2):\n",
    "            for j in range(0,shape[1],2):             \n",
    "                kernel_cb = cb[i:i+2,j:j+2]\n",
    "                kernel_cr = cr[i:i+2,j:j+2]\n",
    "                mean_cb = np.mean(kernel_cb)\n",
    "                mean_cr = np.mean(kernel_cr)\n",
    "                cb[i:i+2,j:j+2] = mean_cb\n",
    "                cr [i:i+2,j:j+2] = mean_cr\n",
    "        ycbcr_img[:,:,1] = cb\n",
    "        ycbcr_img[:,:,2] = cr \n",
    "        return ycbcr_img[:, :, 0], ycbcr_img[:, :, 1], ycbcr_img[:, :, 2]\n",
    "    \n",
    "    def invert(self, inputs):\n",
    "        y, cb, cr = inputs\n",
    "        # your code here \n",
    "        shape = [y.shape[0],y.shape[1],3]\n",
    "        result= np.zeros(shape)\n",
    "        result[:,:,0]=y\n",
    "        result[:,:,1]=cb\n",
    "        result[:,:,2]=cr\n",
    "        return ycbcr2rgb(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test the subsampling: The cr and cb channel should be half the resolution of the y channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, cb, cr = ChromaSubsampling()(img)\n",
    "plt.subplot(141)\n",
    "plt.title('Luminance Y')\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.subplot(142)\n",
    "plt.title('Subsampled Chrominance Cr')\n",
    "plt.imshow(cb, cmap='gray')\n",
    "plt.subplot(143)\n",
    "plt.title('Subsampled Chrominance Cb')\n",
    "plt.imshow(cr, cmap='gray')\n",
    "plt.subplot(144)\n",
    "plt.title('Inverted')\n",
    "plt.imshow(ChromaSubsampling().invert((y,cb,cr)) ,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 2 - DCT on 8x8 blocks - 2 Points\n",
    "Apply DCT on 8x8 blocks. You may use np.fft` or `scipy.fftpack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DCTofBlocks:\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Returns the DCT of the blocks. The position (i, j) is a 2-dim numpy array with the dct coefficents.\"\"\"\n",
    "        # you can use any function from np.fft or scipy.fftpack\n",
    "        # your code here \n",
    "        x ,y = blocks.shape[0], blocks.shape[1]\n",
    "        result = np.zeros_like(blocks)\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                result[i,j] = dct(dct(blocks[i,j].T, norm='ortho').T, norm='ortho') # dct-II ortho\n",
    "        return result.astype(int)\n",
    "    \n",
    "    def invert(self, blocks):\n",
    "        \"\"\"Computes the inverse DCT.\"\"\"\n",
    "        # you can use any function from np.fft or scipy.fftpack\n",
    "        # your code here\n",
    "        result = np.zeros_like(blocks)\n",
    "        x ,y = blocks.shape[0], blocks.shape[1]\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                result[i,j] = idct(idct(blocks[i,j].T, norm='ortho').T, norm='ortho')\n",
    "        return result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print some blocks and their DCT on the y channel\n",
    "y_block = Blocks()(y)\n",
    "y_block_dct = DCTofBlocks()(y_block)\n",
    "\n",
    "# show full image\n",
    "dct_img = Blocks().invert(y_block_dct)\n",
    "plt.imshow(dct_img, cmap='gray', vmax = np.max(dct_img) * 0.01,vmin = 0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# apply inverse DCT\n",
    "a = Blocks().invert(DCTofBlocks().invert(y_block_dct))\n",
    "plt.imshow( a , cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 3 - Quantization - 2 Points\n",
    "Apply quantization on the image with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Quantization:\n",
    "    def __init__(self, threshold=2):\n",
    "        # you can use the Q matrix from Wikipedia or invent your own.\n",
    "\n",
    "        self.q_matrix = np.array([[10,15,25,37,51,66,82,100],\n",
    "                          [15,19,28,39,52,67,83,101],\n",
    "                          [25,28,35,45,58,72,88,105],\n",
    "                          [37,39,45,54,66,79,94,111],\n",
    "                          [51,52,58,66,76,89,103,119],\n",
    "                          [66,67,72,79,89,101,114,130],\n",
    "                          [82,83,88,94,103,114,127,142],\n",
    "                          [100,101,105,111,119,130,142,156]])\n",
    "\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Divides the blocks by the `q_matrix` elementwise. Coefficents under the `threshold` will be set to zero.\"\"\"\n",
    "        result = blocks.copy()\n",
    "        x,y = blocks.shape[0],blocks.shape[1]\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                tmp = result[i,j] // self.q_matrix\n",
    "                np.putmask(tmp,tmp < self.threshold, 0)\n",
    "                result[i,j] = tmp \n",
    "        return result\n",
    "    \n",
    "    def invert(self, blocks):\n",
    "        \"\"\" For inverting multiply your elements piecewise with the Q-Matrix\"\"\"\n",
    "        result = blocks.copy()\n",
    "        x,y = blocks.shape[0],blocks.shape[1]\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                tmp = result[i,j] * self.q_matrix\n",
    "                result[i,j] = tmp \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out Quantization. You should see that with increasing threshold the image becomes more blurry compared to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "quant_1 = Quantization(threshold=2)(y_block_dct) \n",
    "quant_img_1 = Blocks().invert(Quantization().invert(quant_1)) \n",
    "quant_2 = Quantization(threshold=20)(y_block_dct) \n",
    "quant_img_2 = Blocks().invert(Quantization().invert(quant_2)) \n",
    "\n",
    "plt.subplot(331) \n",
    "plt.imshow(quant_img_1, cmap='gray', vmax = np.max(quant_img_1) * 0.01,vmin = 0) \n",
    "plt.subplot(332) \n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(Quantization().invert(quant_1))), cmap='gray') \n",
    "plt.subplot(333) \n",
    "plt.imshow(y, cmap='gray') \n",
    "plt.subplot(334) \n",
    "plt.imshow(quant_img_2, cmap='gray', vmax = np.max(quant_img_2) * 0.01,vmin = 0) \n",
    "plt.subplot(335) \n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(Quantization().invert(quant_2))), cmap='gray') \n",
    "plt.subplot(336) \n",
    "plt.imshow(y, cmap='gray') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 4 - Pick n-th highest - 2 Points\n",
    "Implement the pick n-th highest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PickNthHighest:\n",
    "    def __init__(self, n=1):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, blocks):\n",
    "        \"\"\"Pick the nth-highest frequencies\"\"\"\n",
    "        # your code here\n",
    "        zigzag = ZigZag(8) \n",
    "        zigzag_blocks = zigzag(blocks) \n",
    "        x,y = zigzag_blocks.shape[0], zigzag_blocks.shape[1]\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                zigzag_blocks[i,j] = self.__pickHighest(zigzag_blocks[i,j])\n",
    "\n",
    "        return zigzag.invert(zigzag_blocks)\n",
    "\n",
    "    def __pickHighest(self, lis):\n",
    "        result = np.zeros(len(lis))\n",
    "        result[:self.n] = lis[:self.n]\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def invert(self, blocks):\n",
    "        \"\"\"There is no way to invert this operation. Just return the inputs.\"\"\"\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out pick n-th highest compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pick_1 = PickNthHighest(n=16)(y_block_dct)\n",
    "pick_img_1 = Blocks().invert(pick_1)\n",
    "pick_2 = PickNthHighest(n=5)(y_block_dct)\n",
    "pick_img_2 = Blocks().invert(pick_2)\n",
    "plt.subplot(331)\n",
    "plt.imshow(pick_img_1, cmap='gray', vmax = np.max(pick_img_1) * 0.01,vmin = 0)\n",
    "plt.subplot(332)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(pick_1)), cmap='gray')\n",
    "plt.subplot(333)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.subplot(334)\n",
    "plt.imshow(pick_img_2, cmap='gray', vmax = np.max(pick_img_2) * 0.01,vmin = 0)\n",
    "plt.subplot(335)\n",
    "plt.imshow(Blocks().invert(DCTofBlocks().invert(pick_2)), cmap='gray')\n",
    "plt.subplot(336)\n",
    "plt.imshow(y, cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the jpeg pipeline\n",
    "# for testing you can use only the first ones.\n",
    "# maybe you have to adjust the Quantization threshold settings.\n",
    "jpeg = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=10), ZigZag(8), Compress(np.int8)])\n",
    "\n",
    "img_jpeg = jpeg(img)\n",
    "img_reconstruct = jpeg.invert(img_jpeg)\n",
    "assert img_reconstruct.shape == img.shape\n",
    "# once you implemented ChromaSubsampling.invert this should have colors :)\n",
    "plt.imshow(img_reconstruct / 255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 5 - Pipeline comparison - 2 Points\n",
    "Compare different pipeline setups and complete the tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare the size of the images if the zigzag encoding is removed.\n",
    "# Does the size change if the quantization threshold increases? \n",
    "\n",
    "thresholds = [2,5,10,20]\n",
    " \n",
    "jpeg_size       = [ ]\n",
    "jpeg_size_WZZ   = []\n",
    "for i in thresholds:\n",
    "    jpeg                = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=i), ZigZag(8), Compress(np.int8)])\n",
    "    jpeg_withoutzigzag  = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=i), Compress(np.int8)])\n",
    "    jpeg_img = jpeg(img)\n",
    "    jpeg_img_WZZ = jpeg_withoutzigzag(img)\n",
    "    jpeg_size.append(total_size_jpeg(jpeg_img))\n",
    "    jpeg_size_WZZ.append(total_size_jpeg(jpeg_img_WZZ)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['2','5','10','20']\n",
    "plt.subplot(221)\n",
    "plt.bar(list(range(len(labels))),jpeg_size)\n",
    "plt.title('With ZIGZAG in KB')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(list(range(len(thresholds))), labels)\n",
    "plt.subplot(222)\n",
    "plt.bar(list(range(len(labels))),jpeg_size_WZZ)\n",
    "plt.title('without ZIGZAG in KB')\n",
    "plt.xticks(list(range(len(labels))), labels)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the image quality of the `Quantization` vs. the `PickNthHighest` compressions. Make sure that the outputs\n",
    "# are roughly the same size. Why is one better then the other one?\n",
    "# your code here\n",
    "\n",
    "thresholds = [1,2,5,10] \n",
    "jpeg_size_quan   = []\n",
    "jpeg_size_pickh  = []\n",
    "for i in thresholds:\n",
    "    jpeg_quan           = Jpeg([Blocks(8), DCTofBlocks(), Quantization(threshold=i), ZigZag(8), Compress(np.int8)])\n",
    "    jpeg_pickh          = Jpeg([Blocks(8), DCTofBlocks(), PickNthHighest(n=i), ZigZag(8), Compress(np.int8)])\n",
    "    jpeg_img_quan = jpeg_quan(img)\n",
    "    jpeg_img_pickh = jpeg_pickh(img)\n",
    "\n",
    "\n",
    "    jpeg_size_quan.append(total_size_jpeg(jpeg_img_quan))\n",
    "    jpeg_size_pickh.append(total_size_jpeg(jpeg_img_pickh)) \n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.title('quantization with threshold: ' + str(i))\n",
    "    plt.imshow(jpeg_quan.invert(jpeg_img_quan))\n",
    "    plt.subplot(122)\n",
    "    plt.title('pick highest n=' +str(i))\n",
    "    plt.imshow(jpeg_pickh.invert(jpeg_img_pickh))\n",
    "    plt.show()\n",
    "\n",
    "labels = [ '1','2','5','10']\n",
    "plt.subplot(221)\n",
    "plt.bar(list(range(len(labels))),jpeg_size_quan)\n",
    "plt.title('quantization with threshold in KB')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(list(range(len(labels))), labels)\n",
    "plt.subplot(222)\n",
    "plt.bar(list(range(len(labels))),jpeg_size_pickh)\n",
    "plt.title('pick highest in KB')\n",
    "plt.xticks(list(range(len(labels))), labels)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# your short answer here\n",
    "# With threshold=2 the images has almost the same size. Quantization with threshold 2 looks much better in compare to pick highest with n=2\n",
    "# this effect is reached becuase with pick highest n=2 only the dc and the highest ac value are taken while with quantization threshold=2 \n",
    "# all values are taken, which are > 2. Therefore prob. more AC values are choosen by using the quantization.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondabd88c407e14c40be84e83b5bdd135b46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}